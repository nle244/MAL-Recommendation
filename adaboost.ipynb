{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "new = pd.DataFrame()\n",
    "\n",
    "df_accuracy = pd.read_csv('top_and_bottom_anime.csv')\n",
    "df_accuracy = df_accuracy.drop(columns='Id')\n",
    "df_accuracy = df_accuracy.drop(columns='Rating')\n",
    "df_accuracy = df_accuracy.drop(columns='Demographic')\n",
    "\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in range(df_accuracy.shape[1]):\n",
    "    temp = df_accuracy.iloc[:,i].values.tolist()\n",
    "    temp = le.fit_transform(temp)\n",
    "    new[df_accuracy.columns[i]] = temp\n",
    "\n",
    "df_true = pd.read_csv('anime_matrix_true.csv')\n",
    "rows = df_true[['Id']].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this sets up df_predictions with the same rows as this train/test split\n",
    "x = new\n",
    "y = rows\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "\n",
    "#create cross training split for building the models\n",
    "X_cross_train, X_cross_test, y_cross_train, y_cross_test = train_test_split(x_train, y_train, test_size=0.2, random_state=420)\n",
    "df_predictions = y_cross_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9028/9028 [13:36<00:00, 11.05it/s]\n"
     ]
    }
   ],
   "source": [
    "columns = df_true.columns[1:]\n",
    "predictions = []\n",
    "\n",
    "avg = []\n",
    "for i in tqdm(range(len(columns))):\n",
    "    x = new\n",
    "    y = df_true[columns[i]]\n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "    \n",
    "    #create cross training split for building the models\n",
    "    X_cross_train, X_cross_test, y_cross_train, y_cross_test = train_test_split(x_train, y_train, test_size=0.2, random_state=420)\n",
    "\n",
    "    adaboost = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "    adaboost.fit(X_cross_train,y_cross_train)\n",
    "    avg.append(adaboost.score(X_cross_test,y_cross_test))\n",
    "    predictions.append(list(adaboost.predict(X_cross_test)))\n",
    "\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9028\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('predictions.p', 'wb')\n",
    "pickle.dump(predictions, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('predictions.p', 'wb')\n",
    "predictions = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8262670941340882\n"
     ]
    }
   ],
   "source": [
    "print(sum(avg) / len(avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9029\n"
     ]
    }
   ],
   "source": [
    "print(len(columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9028/9028 [00:06<00:00, 1488.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "for i in tqdm(range(len(columns))):\n",
    "    df_predictions[columns[i]] = predictions[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open a file, where you ant to store the data\n",
    "file = open('adaboost.model', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(adaboost, file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = df_predictions.copy()\n",
    "outputdf.to_csv(f'predictions_matrix_adaboost.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates true_values for only the shows included in this train/test split\n",
    "\n",
    "df_true = pd.read_csv('anime_matrix_true.csv')\n",
    "values = df_true.values\n",
    "anime_ids = list(df_predictions['Id'])\n",
    "true_values = []\n",
    "for anime in anime_ids:\n",
    "    for j in range(len(values)):\n",
    "        if anime in values[j]:\n",
    "            true_values.append(values[j])\n",
    "\n",
    "true_values = numpy.array([numpy.array(xi) for xi in true_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [00:00<00:00, 465.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "663899\n",
      "0.8262670941341046\n",
      "803492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#caluclate accuracy\n",
    "value = 0\n",
    "prediction_matrix = pd.read_csv('predictions_matrix_adaboost.csv')\n",
    "pred_values = prediction_matrix.values\n",
    "\n",
    "num_row = len(pred_values)\n",
    "num_col = len(pred_values[0])\n",
    "for i in tqdm(range(num_row)):\n",
    "    for j in range(1,num_col):          #first item is the anime id, so we skip it\n",
    "        if pred_values[i,j] == true_values[i,j]:\n",
    "            value += 1\n",
    "\n",
    "print(value)\n",
    "#subtracting 1 from column length b/c the first item is the anime id\n",
    "print(value / ((num_row) * (num_col-1)))\n",
    "print((num_row) * (num_col-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fc903fd1a35692d96a4695a6c4f7b57bb80f609b0147f9dc1e34250c7f2a3f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
