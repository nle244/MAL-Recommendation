{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import preprocessing\n",
    "\n",
    "df_user_bag = pd.read_csv('users_bag_of_words_all.csv')\n",
    "df_anime_bag = pd.read_csv('anime_bag_of_words_all.csv')\n",
    "\n",
    "df_anime = pd.read_csv('top_and_bottom_anime.csv')\n",
    "df_anime = df_anime.drop(columns='Id')\n",
    "df_anime = df_anime.drop(columns='Rating')\n",
    "df_anime = df_anime.drop(columns='Demographic')\n",
    "\n",
    "new = pd.DataFrame()\n",
    "le = preprocessing.LabelEncoder()\n",
    "for i in range(df_anime.shape[1]):\n",
    "    temp = df_anime.iloc[:,i].values.tolist()\n",
    "    temp = le.fit_transform(temp)\n",
    "    new[df_anime.columns[i]] = temp\n",
    "\n",
    "df_true = pd.read_csv('anime_matrix_true.csv')\n",
    "rows = df_true[['Id']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9028/9028 [02:01<00:00, 74.14it/s]\n"
     ]
    }
   ],
   "source": [
    "#Creates similarity matrix of all anime for all users\n",
    "count = CountVectorizer()\n",
    "df_similarity = pd.DataFrame()\n",
    "df_similarity = df_true[['Id']].copy()\n",
    "users = df_true.columns[1:]\n",
    "\n",
    "for i in tqdm(range(len(users))):\n",
    "    list_of_bag_of_words = [df_user_bag.loc[i]['bag of words']]\n",
    "\n",
    "    count_matrix = count.fit_transform(df_anime_bag['bag of words'])\n",
    "    try:\n",
    "        count_matrix2 = count.transform(list_of_bag_of_words)\n",
    "    except:\n",
    "        #if user has an empty bag give them a matix of zeros\n",
    "        count_matrix2 = count.transform(['a'])\n",
    "\n",
    "    cosine_sim2 = cosine_similarity(count_matrix, count_matrix2)\n",
    "    # sim_scores = list(enumerate(cosine_sim2))\n",
    "    sim_scores = []\n",
    "    for each in cosine_sim2:\n",
    "        sim_scores.append(each[0])\n",
    "    warnings.simplefilter(action='ignore', category=pd.errors.PerformanceWarning)\n",
    "    df_similarity[users[i]] = sim_scores\n",
    "\n",
    "# print(sim_scores[1][1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('similarity_matrix.p', 'wb')\n",
    "pickle.dump(df_similarity,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "file = open('similarity_matrix.p', 'rb')\n",
    "df_similarity = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write code to traverse matrix and find the average sim score for 1's and 0's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this sets up df_predictions with the same rows as this train/test split\n",
    "x = new\n",
    "y = rows\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "\n",
    "#create cross training split for building the models\n",
    "X_cross_train, X_cross_test, y_cross_train, y_cross_test = train_test_split(x_train, y_train, test_size=0.2, random_state=69)\n",
    "df_predictions = y_cross_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_true.columns[1:]\n",
    "predictions = []\n",
    "\n",
    "avg = []\n",
    "\n",
    "x = new\n",
    "y = df_true[columns[i]]\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2, random_state=42)\n",
    "\n",
    "#create cross training split for building the models\n",
    "X_cross_train, X_cross_test, y_cross_train, y_cross_test = train_test_split(x_train, y_train, test_size=0.2, random_state=69)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8fc903fd1a35692d96a4695a6c4f7b57bb80f609b0147f9dc1e34250c7f2a3f2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
