{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pytest import skip\n",
    "\n",
    "\n",
    "df_user_info = pandas.read_csv('user_watch_list_more_than_20.csv')\n",
    "df_anime = pandas.read_csv('new_anime.csv')\n",
    "df_anime_test = pandas.read_csv('anime_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of anime in test set \n",
    "test_anime = []\n",
    "for i in range(len(df_anime_test)):\n",
    "    test_anime.append(df_anime_test.loc[i]['Id'].replace('\\'',''))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates bag of words with all features\n",
    "def create_soup(x):\n",
    "    result = x['Anime Title']\n",
    "\n",
    "    if x['Studio'] != 'n/a':\n",
    "        result += ' ' + x['Studio']\n",
    "    if x['Source Material'] != 'n/a':\n",
    "        result += ' ' + x['Source Material']\n",
    "    if x['Genre'] != 'n/a':\n",
    "        result += ' ' + x['Genre']\n",
    "    if x['VAs'] != 'n/a':\n",
    "        result += ' ' + x['VAs']\n",
    "\n",
    "    punc = '[],\\'\\\"'\n",
    "    \n",
    "    for ele in result:\n",
    "        if ele in punc:\n",
    "            result = result.replace(ele, \"\")\n",
    "\n",
    "    result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates bag of words with reduced features\n",
    "def create_soup_reduced(x):\n",
    "    result = x['Anime Title']\n",
    "\n",
    "    if x['Studio'] != 'n/a':\n",
    "        result += ' ' + x['Studio']\n",
    "    # if x['Source Material'] != 'n/a':\n",
    "    #     result += ' ' + x['Source Material']\n",
    "    if x['Genre'] != 'n/a':\n",
    "        result += ' ' + x['Genre']\n",
    "    # if x['VAs'] != 'n/a':\n",
    "    #     result += ' ' + x['VAs']\n",
    "\n",
    "    punc = '[],\\'\\\"'\n",
    "    \n",
    "    for ele in result:\n",
    "        if ele in punc:\n",
    "            result = result.replace(ele, \"\")\n",
    "\n",
    "    result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates bag of words with reduced features\n",
    "def create_soup_genres(x):\n",
    "    result = x['Anime Title']\n",
    "\n",
    "    # if x['Studio'] != 'n/a':\n",
    "    #     result += ' ' + x['Studio']\n",
    "    # if x['Source Material'] != 'n/a':\n",
    "    #     result += ' ' + x['Source Material']\n",
    "    if x['Genre'] != 'n/a':\n",
    "        result += ' ' + x['Genre']\n",
    "    # if x['VAs'] != 'n/a':\n",
    "    #     result += ' ' + x['VAs']\n",
    "\n",
    "    punc = '[],\\'\\\"'\n",
    "    \n",
    "    for ele in result:\n",
    "        if ele in punc:\n",
    "            result = result.replace(ele, \"\")\n",
    "\n",
    "    result\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates bag of words as a set\n",
    "def create_soup_set(x):\n",
    "    result = x['Anime Title']\n",
    "\n",
    "    if x['Studio'] != 'n/a':\n",
    "        result += ' ' + x['Studio']\n",
    "    if x['Source Material'] != 'n/a':\n",
    "        result += ' ' + x['Source Material']\n",
    "    if x['Genre'] != 'n/a':\n",
    "        result += ' ' + x['Genre']\n",
    "    if x['VAs'] != 'n/a':\n",
    "        result += ' ' + x['VAs']\n",
    "\n",
    "    punc = '[],\\'\\\"'\n",
    "    \n",
    "    for ele in result:\n",
    "        if ele in punc:\n",
    "            result = result.replace(ele, \"\")\n",
    "\n",
    "    result = set(result.split())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read each user's watch list and creates a bag of words of all anime they watched\n",
    "result = []\n",
    "length = len(df_user_info)\n",
    "\n",
    "# text = 34156\n",
    "# print(text)\n",
    "# print(create_soup(df_anime.loc[df_anime['Id'] == text.index[0]]))\n",
    "\n",
    "for j in tqdm(range(length)):\n",
    "    try:\n",
    "        user = df_user_info.loc[j]['user']\n",
    "        watched = (df_user_info.loc[j]['watched list']).split()\n",
    "        bag = ''\n",
    "        for k in range(len(watched)):\n",
    "            if watched[k] not in test_anime:\n",
    "                try:\n",
    "                    temp = '\\'' + watched[k] + '\\''\n",
    "                    index = df_anime.loc[df_anime['Id'] == temp].index[0]\n",
    "                    bag += ' ' + create_soup_genres(df_anime.loc[index])\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "    result.append([user,bag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = pandas.DataFrame(result, columns=['user','bag of words'])\n",
    "outputdf.to_csv('users_bag_of_words_genres.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read each user's watch list and creates a bag of words of all anime they watched\n",
    "def make_bag(func):\n",
    "    result = []\n",
    "    length = len(df_user_info)\n",
    "\n",
    "    # text = 34156\n",
    "    # print(text)\n",
    "    # print(create_soup(df_anime.loc[df_anime['Id'] == text.index[0]]))\n",
    "\n",
    "    for j in range(1):\n",
    "        try:\n",
    "            user = df_user_info.loc[j]['user']\n",
    "            watched = (df_user_info.loc[j]['watched list']).split()\n",
    "            bag = ''\n",
    "            for k in range(len(watched)):\n",
    "                if watched[k] not in test_anime:\n",
    "                    try:\n",
    "                        temp = '\\'' + watched[k] + '\\''\n",
    "                        index = df_anime.loc[df_anime['Id'] == temp].index[0]\n",
    "                        bag += ' ' + func(df_anime.loc[index])\n",
    "                        print(bag)\n",
    "                    except:\n",
    "                        pass\n",
    "        except:\n",
    "            pass\n",
    "        result.append([user,bag])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create empty dataframe\n",
    "header = ['anime']\n",
    "for i in range(len(df_user_info)):\n",
    "    header.append(df_user_info.loc[i]['user'])\n",
    "\n",
    "result = []\n",
    "for i in range(len(df_anime)):\n",
    "    row = [df_anime.loc[i]['Id'].replace('\\'','')]\n",
    "    for j in range(len(df_user_info)):\n",
    "        row.append(0)\n",
    "    result.append(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = pandas.DataFrame(result, columns=header)\n",
    "outputdf.to_csv('anime_matrix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = pandas.read_csv('anime_matrix.csv')\n",
    "\n",
    "print(df_matrix.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fills in the true values for each anime based on user's watch list\n",
    "u = []\n",
    "for i in range(len(df_user_info)):\n",
    "    u.append(df_user_info.loc[i]['user'])\n",
    "    \n",
    "for j in tqdm(range(len(u))):\n",
    "    try:\n",
    "        w = df_user_info.loc[j][\"watched list\"].split()\n",
    "        for i in range(len(df_anime)):\n",
    "            # print(df_matrix.at[i,'ilampan'])\n",
    "            if df_anime.loc[i]['Id'].replace('\\'','') in w:\n",
    "                df_matrix.at[i,u[j]] = 1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# print(df_matrix.at[0,'ilampan'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = df_user_info.loc[0][\"watched list\"].split()\n",
    "print(temp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = []\n",
    "for i in range(len(df_anime)):\n",
    "    anime.append(df_anime.loc[i]['Id'])\n",
    "\n",
    "users_watched = []\n",
    "header = ['anime']\n",
    "for i in range(len(df_user_info)):\n",
    "    header.append(df_user_info.loc[i]['user'])\n",
    "    try:\n",
    "        users_watched.append(df_user_info.loc[i][\"watched list\"].split())\n",
    "    except:\n",
    "        users_watched.append([])    #append empty list if the user has no watch list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates anime watched true values\n",
    "result = []\n",
    "for i in tqdm(range(len(anime))):\n",
    "    id = anime[i].replace('\\'','')\n",
    "    temp = [id]\n",
    "    for j in range(len(users_watched)):\n",
    "        if id in users_watched[j]:\n",
    "            temp.append(1)\n",
    "        else:\n",
    "            temp.append(0)\n",
    "    result.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((header[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = pandas.DataFrame(result, columns=header)\n",
    "outputdf.to_csv('anime_matrix_true.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp = pandas.read_csv('anime_matrix_true.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spot checking for anime matrix true\n",
    "# out = []\n",
    "# for i in range(len(df_anime)):\n",
    "#     out.append(df_matrix.at[i,'Manzerek'])\n",
    "\n",
    "# print(out)\n",
    "print(df_matrix.loc[4163]['anime'])\n",
    "print(df_matrix.at[4163,'clouds88'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix.to_csv('anime_matrix_temp.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read each user's watch list and creates a bag of words of all anime they watched\n",
    "result = []\n",
    "length = len(df_user_info)\n",
    "\n",
    "# text = 34156\n",
    "# print(text)\n",
    "# print(create_soup(df_anime.loc[df_anime['Id'] == text.index[0]]))\n",
    "\n",
    "for j in tqdm(range(length)):\n",
    "    try:\n",
    "        user = df_user_info.loc[j]['user']\n",
    "        watched = (df_user_info.loc[j]['watched list']).split()\n",
    "        bag = ''\n",
    "        for k in range(len(watched)):\n",
    "            if watched[k] not in test_anime:\n",
    "                try:\n",
    "                    temp = '\\'' + watched[k] + '\\''\n",
    "                    index = df_anime.loc[df_anime['Id'] == temp].index[0]\n",
    "                    bag += ' ' + create_soup_reduced(df_anime.loc[index])\n",
    "                except:\n",
    "                    pass\n",
    "    except:\n",
    "        pass\n",
    "    result.append([user,bag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdf = pandas.DataFrame(result, columns=['user','bag of words'])\n",
    "outputdf.to_csv('users_bag_of_words_reduced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wa = df_user_info.loc[2]['watched list'].split()\n",
    "\n",
    "bag = ''\n",
    "for i in tqdm(range(len(wa))):\n",
    "    if wa[i] not in test_anime:\n",
    "        try:\n",
    "            temp = '\\'' + wa[i] + '\\''\n",
    "            index = df_anime.loc[df_anime['Id'] == temp].index[0]\n",
    "            bag += ' ' + create_soup(df_anime.loc[index])\n",
    "        except:\n",
    "            pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X is the list of anime found in df_anime\n",
    "#y is if the the user watched the anime or not\n",
    "\n",
    "df_anime_x = pandas.read_csv('anime_train.csv')\n",
    "df_anime_y = pandas.read_csv('anime_matrix_true.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['anime', 'ilampan', 'Zephyyr', 'Alister-Dark', 'AMechaDegenarate',\n",
      "       'Matthew_Myers', 'eezairi', 'Neji4460', 'Aguena_Jun', 'andrzejszczelba',\n",
      "       ...\n",
      "       'Jaxelar', 'BitSneakySvenpai', 'PeelyPeelyBoi', 'Tray1990', 'Kilax',\n",
      "       'Darkidda', 'chidoriP', 'snepback', 'Prism8Azure', 'urban_orange'],\n",
      "      dtype='object', length=9242)\n"
     ]
    }
   ],
   "source": [
    "print(df_anime_y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates bag of words with selected features\n",
    "def create_soup_selection(x,studio=False,source=False,genre=False,va=False,all=False):\n",
    "    result = x['Anime Title']\n",
    "\n",
    "    if x['Studio'] != 'n/a' and (studio or all):\n",
    "        result += ' ' + x['Studio']\n",
    "    if x['Source Material'] != 'n/a' and (source or all):\n",
    "        result += ' ' + x['Source Material']\n",
    "    if x['Genre'] != 'n/a' and (genre or all):\n",
    "        result += ' ' + x['Genre']\n",
    "    if x['VAs'] != 'n/a' and (va or all):\n",
    "        result += ' ' + x['VAs']\n",
    "\n",
    "    punc = '[],\\'\\\"'\n",
    "    \n",
    "    for ele in result:\n",
    "        if ele in punc:\n",
    "            result = result.replace(ele, \"\")\n",
    "\n",
    "    result\n",
    "    return result\n",
    "\n",
    "def Sort_Tuple(tup):\n",
    "    # getting length of list of tuples\n",
    "    lst = len(tup)\n",
    "    for i in range(0, lst):\n",
    "            \n",
    "        for j in range(0, lst-i-1):\n",
    "            if (tup[j][1] < tup[j + 1][1]):\n",
    "                temp = tup[j]\n",
    "                tup[j]= tup[j + 1]\n",
    "                tup[j + 1]= temp\n",
    "    return tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3499, 8)\n",
      "(3499, 9242)\n"
     ]
    }
   ],
   "source": [
    "df_anime_y.drop(df_anime_y.tail(876).index,inplace=True)\n",
    "\n",
    "print(df_anime_x.shape)\n",
    "print(df_anime_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_anime_x, df_anime_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9241/9241 [02:41<00:00, 57.39it/s]\n"
     ]
    }
   ],
   "source": [
    "#create user list\n",
    "users = []\n",
    "for i in range(len(df_user_info)):\n",
    "    users.append(df_user_info.loc[i]['user'])\n",
    "\n",
    "#create watch list based on df_anime_y\n",
    "result = []\n",
    "for j in tqdm(range(len(users))):\n",
    "    watched = ''\n",
    "    for i in range(len(df_anime_y)):\n",
    "        if (df_anime_y.at[i,users[j]]):\n",
    "            watched += str(df_anime_y.loc[i]['Id']) + ' '\n",
    "    result.append([users[j],watched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          Id  ilampan  Zephyyr  Alister-Dark  AMechaDegenarate  Matthew_Myers  \\\n",
      "1650  23799        0        0             0                 0              0   \n",
      "2456   1810        0        0             0                 0              0   \n",
      "2232    658        0        0             0                 0              0   \n",
      "1945   5129        0        0             0                 0              0   \n",
      "309   36522        0        0             0                 0              0   \n",
      "...     ...      ...      ...           ...               ...            ...   \n",
      "3127  10338        0        0             0                 0              0   \n",
      "744   40368        0        0             0                 0              0   \n",
      "631   38804        0        0             0                 0              0   \n",
      "1557  20085        0        0             0                 0              0   \n",
      "2213    612        0        0             0                 0              0   \n",
      "\n",
      "      eezairi  Neji4460  Aguena_Jun  andrzejszczelba  ...  Jaxelar  \\\n",
      "1650        0         0           0                0  ...        0   \n",
      "2456        0         0           0                0  ...        0   \n",
      "2232        0         0           0                0  ...        0   \n",
      "1945        0         0           0                0  ...        0   \n",
      "309         0         0           0                0  ...        0   \n",
      "...       ...       ...         ...              ...  ...      ...   \n",
      "3127        0         0           0                0  ...        0   \n",
      "744         0         0           0                0  ...        0   \n",
      "631         0         0           0                0  ...        0   \n",
      "1557        0         0           0                0  ...        0   \n",
      "2213        0         0           0                0  ...        0   \n",
      "\n",
      "      BitSneakySvenpai  PeelyPeelyBoi  Tray1990  Kilax  Darkidda  chidoriP  \\\n",
      "1650                 0              0         0      0         0         0   \n",
      "2456                 0              0         0      1         0         0   \n",
      "2232                 0              0         0      0         0         0   \n",
      "1945                 0              0         0      0         0         0   \n",
      "309                  0              0         0      0         0         0   \n",
      "...                ...            ...       ...    ...       ...       ...   \n",
      "3127                 0              0         0      0         0         0   \n",
      "744                  0              0         0      0         0         0   \n",
      "631                  0              0         0      0         0         0   \n",
      "1557                 0              0         0      0         0         0   \n",
      "2213                 0              0         0      0         0         0   \n",
      "\n",
      "      snepback  Prism8Azure  urban_orange  \n",
      "1650         0            0             0  \n",
      "2456         0            0             0  \n",
      "2232         0            0             0  \n",
      "1945         0            0             0  \n",
      "309          0            0             0  \n",
      "...        ...          ...           ...  \n",
      "3127         0            1             0  \n",
      "744          0            0             0  \n",
      "631          0            0             0  \n",
      "1557         0            0             0  \n",
      "2213         0            0             0  \n",
      "\n",
      "[700 rows x 9242 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(y_test.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_mini_watch_list \u001b[39m=\u001b[39m pandas\u001b[39m.\u001b[39mDataFrame(result, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39muser\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwatch list\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m test_anime \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X_test)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'result' is not defined"
     ]
    }
   ],
   "source": [
    "df_mini_watch_list = pandas.DataFrame(result, columns=['user', 'watch list'])\n",
    "\n",
    "test_anime = []\n",
    "for i in range(len(X_test)):\n",
    "    test_anime.append(X_test.iloc[i]['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9241/9241 [18:25<00:00,  8.36it/s]\n",
      "100%|██████████| 3499/3499 [00:00<00:00, 6127.97it/s]\n"
     ]
    }
   ],
   "source": [
    "#read each user's watch list and creates a bag of words of all anime they watched\n",
    "user_bag_result = []\n",
    "length = len(users)\n",
    "\n",
    "for j in tqdm(range(length)):\n",
    "    user = df_mini_watch_list.loc[j]['user']\n",
    "    watched = (df_mini_watch_list.loc[j]['watch list']).split()\n",
    "    bag = ''\n",
    "    for k in range(len(watched)):\n",
    "        if watched[k] not in test_anime:\n",
    "            try:\n",
    "                temp = '\\'' + watched[k] + '\\''\n",
    "                index = df_anime.loc[df_anime['Id'] == temp].index[0]\n",
    "                bag += ' ' + create_soup_selection(df_anime.loc[index],genre=True,studio=True)\n",
    "            except:\n",
    "                pass\n",
    "    user_bag_result.append([user,bag])\n",
    "\n",
    "#creates a bag of words for each anime\n",
    "anime_bag_result = []\n",
    "for i in tqdm(range(len(df_anime_x))):\n",
    "    anime = df_anime_x.iloc[i]['Id'].replace('\\'','')\n",
    "    bag = create_soup_selection(df_anime_x.iloc[i],genre=True,studio=True)\n",
    "    anime_bag_result.append([anime,bag])\n",
    "\n",
    "#output the user bag of words to csv\n",
    "outputdf = pandas.DataFrame(user_bag_result, columns=['user','bag of words'])\n",
    "outputdf.to_csv('users_bag_of_words_genre_studio.csv', index=False)\n",
    "\n",
    "#output the anime bag of words to csv\n",
    "outputdf = pandas.DataFrame(anime_bag_result, columns=['Id','bag of words'])\n",
    "outputdf.to_csv('anime_bag_of_words_genre_studio.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anime_x_temp = df_anime_x.copy()\n",
    "\n",
    "# df_anime_x_temp = df_anime_y[['ilampan']].copy()\n",
    "user_column = df_anime_y['ilampan']\n",
    "df_anime_x_temp['ilampan'] = user_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_anime_y.columns\n",
    "users = []\n",
    "for col in columns[1:]:\n",
    "    users.append(col)\n",
    "\n",
    "rows =[]\n",
    "for i in range(len(X_test)):\n",
    "    rows.append(X_test.iloc[i]['Id'].replace('\\'',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'users' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m user_column \u001b[39m=\u001b[39m df_anime_y[users[\u001b[39m0\u001b[39m]]\n\u001b[0;32m      2\u001b[0m df_anime_x_temp[users[\u001b[39m0\u001b[39m]] \u001b[39m=\u001b[39m user_column\n",
      "\u001b[1;31mNameError\u001b[0m: name 'users' is not defined"
     ]
    }
   ],
   "source": [
    "user_column = df_anime_y[users[0]]\n",
    "df_anime_x_temp[users[0]] = user_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creates a bag of words for each anime\n",
    "anime_bag_result = []\n",
    "for i in tqdm(range(len(df_anime_x))):\n",
    "    anime = df_anime_x.iloc[i]['Id'].replace('\\'','')\n",
    "    bag = create_soup_selection(df_anime_x.iloc[i],genre=True,studio=True)\n",
    "    anime_bag_result.append([anime,bag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ilampan\n",
      "700\n"
     ]
    }
   ],
   "source": [
    "print(users[0])\n",
    "print(len(rows))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(list1, list2):\n",
    "    intersection = len(list(set(list1).intersection(list2)))\n",
    "    union = (len(list1) + len(list2)) - intersection\n",
    "    return float(intersection / union)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                                                            '1810'\n",
      "Anime Title                                 'KyoushiroutoTowanoSora'\n",
      "Rating                                                          6.42\n",
      "Studio                                                           TNK\n",
      "Source Material                                                Manga\n",
      "Demographic                                                'Shounen'\n",
      "Genre                                ['Drama', 'Romance', 'Shounen']\n",
      "VAs                ['MatsuokaYuki', 'YukiKonishi', 'KonishiKatsuy...\n",
      "Name: 2456, dtype: object\n"
     ]
    }
   ],
   "source": [
    "df_anime_x_temp = df_anime_x.copy()\n",
    "\n",
    "# df_anime_x_temp = df_anime_y[['ilampan']].copy()\n",
    "user_column = df_anime_y[users[0]]\n",
    "df_anime_x_temp[users[0]] = user_column\n",
    "\n",
    "print(X_test.iloc[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 700/700 [10:16<00:00,  1.14it/s]\n"
     ]
    }
   ],
   "source": [
    "all_distances = []\n",
    "for j in tqdm(range(len(X_test))):\n",
    "    bag1 = create_soup_selection(X_test.iloc[j],all=True).split()\n",
    "    distances = []\n",
    "    for i in range(len(X_train)):\n",
    "        bag2 = create_soup_selection(X_train.iloc[i],all=True).split()\n",
    "        distances.append((X_train.iloc[i]['Id'].replace('\\'',''),jaccard(list(bag1),list(bag2))))\n",
    "    Sort_Tuple(distances)\n",
    "    all_distances.append(distances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open a file, where you ant to store the data\n",
    "file = open('knn_distances', 'wb')\n",
    "\n",
    "# dump information to that file\n",
    "pickle.dump(all_distances, file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# open a file, where you stored the pickled data\n",
    "file = open('knn_distances', 'rb')\n",
    "\n",
    "# dump information to that file\n",
    "all_distances = pickle.load(file)\n",
    "\n",
    "# close the file\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n",
      "ilampan\n"
     ]
    }
   ],
   "source": [
    "print(len(all_distances))\n",
    "print(users[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/9241 [00:11<3:37:23,  1.41s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [32], line 33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(neighbors):\n\u001b[0;32m     32\u001b[0m     row \u001b[39m=\u001b[39m df_anime_y[\u001b[39m'\u001b[39m\u001b[39mId\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m numpy\u001b[39m.\u001b[39mint64(distances[i][\u001b[39m0\u001b[39m])\n\u001b[1;32m---> 33\u001b[0m     \u001b[39msum\u001b[39m \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m((df_anime_y\u001b[39m.\u001b[39;49mloc[row][col]))\n\u001b[0;32m     34\u001b[0m \u001b[39m#make prediction based off avg of sum\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39msum\u001b[39m \u001b[39m/\u001b[39m neighbors) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py:1074\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1071\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1073\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1074\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py:1293\u001b[0m, in \u001b[0;36m_LocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1291\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_slice_axis(key, axis\u001b[39m=\u001b[39maxis)\n\u001b[0;32m   1292\u001b[0m \u001b[39melif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 1293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getbool_axis(key, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1294\u001b[0m \u001b[39melif\u001b[39;00m is_list_like_indexer(key):\n\u001b[0;32m   1295\u001b[0m \n\u001b[0;32m   1296\u001b[0m     \u001b[39m# an iterable multi-selection\u001b[39;00m\n\u001b[0;32m   1297\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(labels, MultiIndex)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexing.py:1094\u001b[0m, in \u001b[0;36m_LocationIndexer._getbool_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1092\u001b[0m key \u001b[39m=\u001b[39m check_bool_indexer(labels, key)\n\u001b[0;32m   1093\u001b[0m inds \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 1094\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_take_with_is_copy(inds, axis\u001b[39m=\u001b[39;49maxis)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:3903\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3895\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m   3896\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3897\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3898\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3901\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3902\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3903\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   3904\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3905\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\generic.py:3887\u001b[0m, in \u001b[0;36mNDFrame._take\u001b[1;34m(self, indices, axis, convert_indices)\u001b[0m\n\u001b[0;32m   3880\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3881\u001b[0m \u001b[39mInternal version of the `take` allowing specification of additional args.\u001b[39;00m\n\u001b[0;32m   3882\u001b[0m \n\u001b[0;32m   3883\u001b[0m \u001b[39mSee the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3884\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3885\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m-> 3887\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[0;32m   3888\u001b[0m     indices,\n\u001b[0;32m   3889\u001b[0m     axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis),\n\u001b[0;32m   3890\u001b[0m     verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   3891\u001b[0m     convert_indices\u001b[39m=\u001b[39;49mconvert_indices,\n\u001b[0;32m   3892\u001b[0m )\n\u001b[0;32m   3893\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py:969\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify, convert_indices)\u001b[0m\n\u001b[0;32m    966\u001b[0m     indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[0;32m    968\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\u001b[39m.\u001b[39mtake(indexer)\n\u001b[1;32m--> 969\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreindex_indexer(\n\u001b[0;32m    970\u001b[0m     new_axis\u001b[39m=\u001b[39;49mnew_labels,\n\u001b[0;32m    971\u001b[0m     indexer\u001b[39m=\u001b[39;49mindexer,\n\u001b[0;32m    972\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[0;32m    973\u001b[0m     allow_dups\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    974\u001b[0m     copy\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    975\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\internals\\managers.py:761\u001b[0m, in \u001b[0;36mBaseBlockManager.reindex_indexer\u001b[1;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, only_slice, use_na_proxy)\u001b[0m\n\u001b[0;32m    758\u001b[0m new_mgr \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mfrom_blocks(new_blocks, new_axes, new_refs)\n\u001b[0;32m    759\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    760\u001b[0m     \u001b[39m# We can avoid the need to rebuild these\u001b[39;00m\n\u001b[1;32m--> 761\u001b[0m     new_mgr\u001b[39m.\u001b[39m_blknos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblknos\u001b[39m.\u001b[39;49mcopy()\n\u001b[0;32m    762\u001b[0m     new_mgr\u001b[39m.\u001b[39m_blklocs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblklocs\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    763\u001b[0m \u001b[39mreturn\u001b[39;00m new_mgr\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# distances = all_distances[0]\n",
    "# Sort_Tuple(distances)\n",
    "\n",
    "# print(distances[0:5])\n",
    "\n",
    "# print(users[0])\n",
    "#make empty prediction matrix\n",
    "#add anime Id column\n",
    "#for every user\n",
    "#   for each list of distances\n",
    "#       for 1 to number of neighbors\n",
    "#           read user's watch value and add to sum\n",
    "#       find value of sum and divide by k\n",
    "#       if sum / k is >= 0.5 append 1, else append 0\n",
    "#   append user name and list of predictions to prediction matrix\n",
    "\n",
    "# print(type(distances[1][0]))\n",
    "# temp = df_anime_y.loc[df_anime_y['Id'] == 32937]['ilampan']\n",
    "# print(df_anime_y.loc[df_anime_y['Id'] == 32937])\n",
    "neighbors = 5\n",
    "df_predictions = pandas.DataFrame()\n",
    "df_predictions['Id'] = rows\n",
    "prediction_result = []\n",
    "for j in tqdm(range(len(users))):\n",
    "    col = users[j]\n",
    "    predictions = []\n",
    "    for k in range(len(all_distances)):\n",
    "        sum = 0\n",
    "        distances = all_distances[k]\n",
    "        #compute the sum\n",
    "        for i in range(neighbors):\n",
    "            row = df_anime_y['Id'] == numpy.int64(distances[i][0])\n",
    "            sum += float((df_anime_y.loc[row][col]))\n",
    "        #make prediction based off avg of sum\n",
    "        if (sum / neighbors) >= 0.5:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    # df_predictions[col] = predictions\n",
    "    prediction_result.append(predictions)\n",
    "\n",
    "# print('sum = ',sum/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(df_predictions)):\n",
    "#     print(df_predictions.loc[i])\n",
    "\n",
    "outputdf = df_predictions.copy()\n",
    "outputdf.to_csv('predictions_matrix_5nn_mini.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of          Id\n",
      "0        Id\n",
      "1     32937\n",
      "2     33206\n",
      "3     32615\n",
      "4     33487\n",
      "...     ...\n",
      "3495  16241\n",
      "3496  17681\n",
      "3497  17249\n",
      "3498  17731\n",
      "3499  17849\n",
      "\n",
      "[3500 rows x 1 columns]>\n"
     ]
    }
   ],
   "source": [
    "df_predictions = pandas.DataFrame()\n",
    "df_predictions['Id'] = rows\n",
    "print(df_predictions.head)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ab5f0538989203499ae8c09796501035f37df75f796f45e9c3b3f0fac523391"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
